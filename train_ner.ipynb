{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00995b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_data as ut\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "tokenizerBERT = BertTokenizer.from_pretrained('pranav-s/MaterialsBERT', model_max_length=512)\n",
    "modelBERT = BertForMaskedLM.from_pretrained('pranav-s/MaterialsBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6413d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'POLYMER': 1,\n",
    "           'ORGANIC': 2,\n",
    "           'MONOMER': 3,\n",
    "           'PROP_NAME': 4,\n",
    "           'INORGANIC': 5,\n",
    "           'MATERIAL_AMOUNT': 6,\n",
    "           'POLYMER_FAMILY': 7,\n",
    "           'PROP_VALUE': 8,\n",
    "           'O': 0}\n",
    "max_length = 512\n",
    "batch_size = 10\n",
    "class NERBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = modelBERT.base_model\n",
    "        self.linear = nn.Linear(768, len(classes) + 1)\n",
    "        \n",
    "    def forward(self, token):\n",
    "        encoder_output= self.bert(token)\n",
    "        linear_output = self.linear(encoder_output.last_hidden_state[0,:,:])\n",
    "        class_output = F.softmax(linear_output, dim=1)\n",
    "        return class_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784af378",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERBERTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb25e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = ut.read_data('train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4cb1c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,     1,  1927, 16745,     1,     1,    13,    12,     1,    13,\n",
       "          1982,  3845,  2193,  8862,  4860,    12,     1,    16,     1,    71,\n",
       "          1930,     1,    71,    13,    16,  3824,    16,  7111,    16,  1930,\n",
       "          5821,  2860,    18,     1,  2555,  2778,  2258,  3845,  1920,  3604,\n",
       "          1927,  2303,     1,  1958,     1,    12,     1,    16,     1,  1930,\n",
       "             1,    13,    16, 14119,  1977, 10974,  2810,  1942,  2496,  3959,\n",
       "            17,  4927, 20596,    18,     1,  1930,  5056, 15422, 20364,  4146,\n",
       "          2019,  3259,    89,     1,  4504,  1988,  2228,  9350,  1922,  4860,\n",
       "          2032,  3216,  1958, 14119,     1,  2785,  2452,  1942, 26283,     1,\n",
       "            18,     1,    16,     1,  4985,  1956,     1,  3751,     9, 14119,\n",
       "          9826,    34, 22533,  7104,  8137,  1958,  2321,     1,    18,     1,\n",
       "         23277,  4146,  2037,  3772,    17,  9310, 23277,  3235,  6645,  1927,\n",
       "          1920,  9350,  1922,     1, 12506,  1958,  2136,     1,    19, 14119,\n",
       "         10755,     1, 26283,     1,    18,     1, 12506,  9350,    16,  2469,\n",
       "          4252,  1956,  1920, 23342,  9350,  3045,  3454,  6809, 20364,    16,\n",
       "          3394,    43,  4457,  1942,  5734,  1920,  8829, 23277,     1,  6601,\n",
       "          8320,  1942,  1920,  3399,  8828,  3378,  1922, 14119,     1,     1,\n",
       "            18,     1,  5630,  3404,  1988,  6601,  1977,  2567,  2253,  2715,\n",
       "          2254, 23277,  1922,  7426,  5056, 15422,  4860,  1922,     1,     1,\n",
       "            16,  1930,  3404,    43,  2551,    16,  2876,  2941,  9079,    16,\n",
       "          5045,  1958,  4612,  4860,    18,     1,  4146,  1958,  2136,     1,\n",
       "            19, 14119,  2785,  5987,     1,  1930,  3378,  1922,  3294,  3776,\n",
       "          1958,  1920, 10755,  2452,  1942, 26283,     1,    18,     1,  3379,\n",
       "          1977,  3499,  1956,  1920,  4305,  4860,  3879,  1958,  1920,     1,\n",
       "          2785,    16,  2597,  3171,  6100,  5516,  2154, 12448,  8828,  1942,\n",
       "          1925, 11231,  6816,  1990,  3294,  3776,    18,     1,    16, 12506,\n",
       "          7468,  3045,  3454,  2321, 20364,  1930,  8660, 23277,  2860, 22965,\n",
       "          1920, 10316,  1988, 14119,     1,    43,  7717,  1927,  1920,  5799,\n",
       "          3294,  3776,    12,     1,    16,     1,     6,     1,     6,    13,\n",
       "          1922,  1920,     1,  4526,    18,     1,  1922,  1920,  7136,  4832,\n",
       "          3449,    12,     1,    49,    13,  3045,  3454,  5611,  7415, 23890,\n",
       "          1930,  5760,  5821,  2333,  1982,  2528,  1958,  2136,     1,    19,\n",
       "         14119, 10755,  2452,  1942, 26283,     1,    16,  4281,     1,  3379,\n",
       "          6966,  1922,  1920,     1,  3360,  2019,  3259,    89,     1,    18,\n",
       "             1,     1,    49,  6816,  1982,  7098,  2910,  2338,  1920,  3110,\n",
       "          3109,  2193,  1920,     1,  6702,    16,  2154,  7079,  2851,  1927,\n",
       "          1920,  7358,  4594,     1,    49,     1,    18,     1, 10091,    16,\n",
       "          2228,     1,    49,  9350,  1985,  2528,  1958,  1920,     1,    19,\n",
       "         14119, 10755,  1956,  2149, 14119,  3919,  2810,  1942,  1920,  2330,\n",
       "             1,    49,  1927,  7358, 14119,    12,     1,    16,     1,    89,\n",
       "             1,    13,    18,     1,  5821,  5630,  1927,  1920,  2316,    17,\n",
       "         11638,  4666,    12,   161,    13,  9157,  1958,  1920,     1,    19,\n",
       "         14119, 10755,  3675,  8090,  2460,  1920,  2495,  1927, 14119,  1990,\n",
       "          1920,  8829,     1,  4028, 10551,  1922,  1920,     1,  3360,    18,\n",
       "             1,  2019,  3137,  6458,  5563,  7063,  1927,  2321,  1920,  2936,\n",
       "         12887,  1930,     1,  2458,  1956,  1920,   161,  9157,    16,  1930,\n",
       "          3404,  1988,  2321,  3673,  3714,  1956,  3605, 14119,  3919,    18,\n",
       "             1,  6296, 10316,  5110,  3454, 14119, 13556,  1920,  7971,  6335,\n",
       "             1,  6269,  1922,  1920,     1,    19, 14119,  2785,    16,  1930,\n",
       "         10634,  1942,  5895,  1920,  6601,  9350,  2452,  1942, 26283,     1,\n",
       "            18,     1,  4180,  1988,  1920,  8828,  9350,  3864,  2037,     1,\n",
       "          1927,     1, 16786,  2037,  9350,  1922,  2321, 12506,    12,     1,\n",
       "            16,     6, 13356, 12919,     6,    13,  1930, 23342,    12,     1,\n",
       "            16, 22356,  7971,  6335,     1,    13,  1977, 19012,    16,  3328,\n",
       "         23955,    16,  1920,  2288,  3531,  2032,     1,    18,     1, 14119,\n",
       "             1, 10634,  1966,    43,  6842,  4778,  1942,  3326,  1920,  7104,\n",
       "          3879,  1927,     1,    16,  2321,  8137,  1930, 22841, 26157,  5516,\n",
       "            18,     1,     1,  1927, 14119,  2409, 20599,    17,  4587,  1977,\n",
       "            43,  2991,  1988,  4902,  1998,  8441,    16,  3328,     1,  1977,\n",
       "          2444, 16724,  3216,  2469,  1920,     1,  9826, 11489, 10845,  1956,\n",
       "          1920,  4593,    18,     1,  1920, 21122,  1927,  1920,  4305,  7104,\n",
       "          3879,    16,  1920,     1,    49,  3378,  1958,  1920,     1,    19,\n",
       "         14119,  2785,  1977,    43, 17197,  2810,  1942,  1920,  6064,  2330,\n",
       "             1,    49,  1958,  7358,     1,    18,     1,  6296,     1,    49,\n",
       "          3378,  1922,  1920, 14119,  3165,  2785,  1977,  2520,  7006,  2469,\n",
       "         12703,  1977,  6373,    16,  3328,  3224,  6387,     1,  1922,     1,\n",
       "          1930,  3328,  3224,  8655,  1922,  1920,  2482,    17,  2485,  5990,\n",
       "          4667, 24121, 24484,    18,     1,  3066,  1998,     1,    16,  2406,\n",
       "            16,  1988,  1920,  3214,  2161,  2444, 24609,  1920,  2495,  1927,\n",
       "         14119,     1,  4667, 16745,     1,    16,  1930,  1988,  1920,  2990,\n",
       "          1927,  2321, 28007,  1930,  7148,  2832,  4087, 17710,  1920,     1,\n",
       "            49,  9350,  2528,  1922,  1920,  3214,  2778, 20259,  1942,  1920,\n",
       "         16745,  3360,    18,     1, 19012,  4560,  3537,  2832,  1998,  1942,\n",
       "          4482,  1920,  2495,  1927, 14119,     1,  1990,  2321,     1,  1930,\n",
       "             1, 10823,     1,  2785,    16,  3328,     1,    17,     1, 21143,\n",
       "          2427,  4075,    18,     1,    16,  2176,  2832,  1998,  1927,  4501,\n",
       "          1942,  5734,  1920,  2495,  1927, 14119,  1990,  1920,  2559,  3193,\n",
       "          2322,  1927, 28007,  1922,     1,    16,  1930,  1942,  4482,  1920,\n",
       "         16309,  1922,  4860,  3378,  1988,  2112,  1998, 16274,  3454,  3921,\n",
       "          1927,  2321,     1,  1930, 15416, 12616,    18,     1,  2176,  1977,\n",
       "          4680,  1942,  2161,  2427,  9881,  2919,    16,  1920,  3214,  2778,\n",
       "          4558,  1925,  2715,     6,  5170,    17,  3087,     6,  5630,  1988,\n",
       "         23955,  4902, 11763,  1956,  1920, 14881, 16745,  6076,    18]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_tensors_all_list[460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08f7bcc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 512] at entry 0 and [1, 829] at entry 460",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m token_tensors_all_list \u001b[38;5;241m=\u001b[39m [ut\u001b[38;5;241m.\u001b[39mlist2token(tokenizerBERT, d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m], max_length) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data_list]\n\u001b[0;32m----> 2\u001b[0m token_tensors_all \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_tensors_all_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m token_tensors_all\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 512] at entry 0 and [1, 829] at entry 460"
     ]
    }
   ],
   "source": [
    "token_tensors_all_list = [ut.list2token(tokenizerBERT, d['words'], max_length) for d in data_list]\n",
    "token_tensors_all = torch.stack(token_tensors_all_list, dim=1)\n",
    "token_tensors_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4790bd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_tensor = ut.list2token(tokenizerBERT, data['words'], max_length)\n",
    "token_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aff78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366bff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "train_losses = []\n",
    "for epoch in range(epochs):\n",
    "    for data in data_list[:100]:\n",
    "        token = ut.list2token(tokenizerBERT, data['words'], max_length)\n",
    "        prediction = model(token)\n",
    "        target = torch.tensor(ut.cat2digit(classes, data['ner'], max_length))\n",
    "        loss = criterion(prediction, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_losses.append(loss)\n",
    "    print(f'epoch: {epoch:2}  loss: {loss.item():10.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b0be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae7bf36f5dbf0881f49ddb9294144751d972892b8d789f369fe04d31bdb1fea1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
