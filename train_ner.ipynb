{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00995b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_data as ut\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "tokenizerBERT = BertTokenizer.from_pretrained('pranav-s/MaterialsBERT', model_max_length=512)\n",
    "modelBERT = BertForMaskedLM.from_pretrained('pranav-s/MaterialsBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6413d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'POLYMER': 1,\n",
    "           'ORGANIC': 2,\n",
    "           'MONOMER': 3,\n",
    "           'PROP_NAME': 4,\n",
    "           'INORGANIC': 5,\n",
    "           'MATERIAL_AMOUNT': 6,\n",
    "           'POLYMER_FAMILY': 7,\n",
    "           'PROP_VALUE': 8,\n",
    "           'O': 0}\n",
    "max_length = 512\n",
    "batch_size = 3\n",
    "class NERBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = modelBERT.base_model\n",
    "        self.linear = nn.Linear(768, len(classes) + 1)\n",
    "        \n",
    "    def forward(self, token):\n",
    "        encoder_output= self.bert(token)  # torch.LongTensor of shape (batch_size, sequence_length)\n",
    "        linear_output = self.linear(encoder_output.last_hidden_state)\n",
    "        class_output = F.softmax(linear_output, dim=2)\n",
    "        return class_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784af378",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERBERTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb25e7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 100\n",
    "data_list = ut.read_data('train.json', max_length)[:num_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8eceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tensors_all_list = [ut.list2token(tokenizerBERT, d['words'], max_length) for d in data_list]\n",
    "data = torch.cat(token_tensors_all_list, dim=0)\n",
    "data_batches = ut.to_batches(data, batch_size)\n",
    "target_tensors_all_list = [ut.cat2digit(classes, d['ner'], max_length) for d in data_list]\n",
    "target = torch.stack(target_tensors_all_list, dim=0)\n",
    "target_batches = ut.to_batches(target, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94aff78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe2ccfe84d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.1, 1, 1, 1, 1, 1, 1, 1, 1, 0.1]))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "torch.manual_seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366bff7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  batch:   0  loss: 2.319016 \n",
      "epoch:  0  batch:   5  loss: 2.003860 \n",
      "epoch:  0  batch:  10  loss: 2.056751 \n",
      "epoch:  0  batch:  15  loss: 2.050579 \n",
      "epoch:  0  batch:  20  loss: 2.117112 \n",
      "epoch:  0  batch:  25  loss: 2.175548 \n",
      "epoch:  0  batch:  30  loss: 2.160239 \n",
      "epoch:  1  batch:   0  loss: 2.083002 \n",
      "epoch:  1  batch:   5  loss: 2.072974 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#acc = ut.accuracy(0, len(classes), y_pred, y)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train_losses = []\n",
    "for epoch in range(epochs):\n",
    "    for b, X in enumerate(data_batches):\n",
    "        y_pred = model(X)\n",
    "        y_pred = torch.swapaxes(y_pred, 1, 2)\n",
    "        y = target_batches[b]\n",
    "        # Correct entity name prediction\n",
    "#         \n",
    "        loss = criterion(y_pred, y)\n",
    "        #acc = ut.accuracy(0, len(classes), y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if b % 5 == 0:\n",
    "            print(f'epoch: {epoch:2}  batch: {b:3}  loss: {loss.item():.6f} ') #  accuracy: {acc:.4f}\n",
    "#             print(predicted_classes)\n",
    "#             print(true_classes)\n",
    "    train_losses.append(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b91e2ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# indices = ((0 < y) & (y < 9)).nonzero(as_tuple=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[indices[0], indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred[indices[0], :, indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cea10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = ((0 < y) & (y < len(classes))).nonzero(as_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, max_indices = y_pred[indices[0], :, indices[1]].max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25975611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c646ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true = y[indices[0], indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd204e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.eq(max_indices, true).sum() / true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae7bf36f5dbf0881f49ddb9294144751d972892b8d789f369fe04d31bdb1fea1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
